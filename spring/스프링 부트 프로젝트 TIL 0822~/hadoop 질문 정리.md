하둡이란 것이 데이터를 분산하여 정리하는 프로그램?서버인것 같은데 클러스터를 형성하는 것이 scale out 방식으로 대용량 데이터 처리를 수월하게 하기 위한 것이 맞나요? 그리고 저희가 이것을 이용하는 것이 데이터를 이것으로 분산한 결과를 가지고 프로젝트를 수행하는 것이면 그 데이터를 분석한 이후로는 어떤 사용 방법이 있는지?

블럭 단위로 mapper가 실행 코어가 여러개 있으면 하나의 데이터노드가 있어도 동시에 처리

컴파일 방법은 다른 것 써도 되고 가장 많이 쓰는 ant를 사용했다
